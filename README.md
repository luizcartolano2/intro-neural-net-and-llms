# Introduction to Neural Networks and LLMs

This repository contains materials, code, and resources related to an introductory course on Neural Networks and Large Language Models (LLMs). The goal of this course is to provide a foundational understanding of neural networks and their applications, with a focus on modern advancements in LLMs.

## Contents

- **Lecture Notes**: Summaries and key points from the course lectures.
- **Code Examples**: Python scripts and Jupyter notebooks demonstrating key concepts.
- **Assignments**: Practical exercises to reinforce learning.
- **Datasets**: Sample datasets used for training and testing models.
- **Resources**: Additional reading materials, references, and links.

## Prerequisites

- Basic knowledge of Python programming.
- Familiarity with linear algebra, calculus, and probability is recommended.
- No prior experience with neural networks or machine learning is required.

## Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/luizcartolano2/intro-neural-networks-llms.git
   cd intro-neural-networks-llms
   ```
2. Create a virtual environment (optional but recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```
3. Install the required packages:
   ```bash
    pip install -r requirements.txt
    ```

## Topics Covered
1. Introduction to Neural Networks
   - Basic concepts and terminology
   - Perceptrons and multi-layer networks
   - Activation functions

2. Deep Learning Fundamentals
   - Backpropagation algorithm
   - Loss functions and optimization
   - Regularization techniques

3. Introduction to Large Language Models
   - Overview of LLMs and their architecture
   - Transformer models and attention mechanisms
   - Pre-training and fine-tuning

## License
This repository is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

## Acknowledgments
Special thanks to the course instructors and contributors for their guidance and support.
